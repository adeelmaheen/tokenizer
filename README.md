# üî§ AI Tokenizer Pro

A professional-grade text tokenization application built with Streamlit and Hugging Face Transformers. Analyze and visualize how different AI models tokenize your text with a beautiful, modern interface.

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ‚ú® Features

### Core Functionality
- ü§ñ **Multiple Tokenizer Models**: Support for GPT-2, BERT, LLaMA 2, Mistral, T5, and more
- üéØ **Real-time Tokenization**: Instant token counting and analysis
- üìä **Comprehensive Statistics**: Word count, character count, token-to-word ratios
- üîç **Token Visualization**: See individual tokens with their IDs
- üìú **History Tracking**: Keep track of all tokenization sessions
- üíæ **Export Options**: Download results in JSON, CSV, or TXT format

### Advanced Features
- ‚ö° **Caching**: Fast loading with model caching
- üé® **Professional UI**: Modern gradient design with interactive elements
- üìà **Analytics Dashboard**: Track usage patterns and statistics
- üîÑ **No API Key Required**: Runs completely offline after initial model download
- üì± **Responsive Design**: Works on desktop and mobile devices

## üöÄ Quick Start

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/ai-tokenizer-pro.git
   cd ai-tokenizer-pro
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

   Or install manually:
   ```bash
   pip install streamlit transformers pandas torch
   ```

3. **Run the application**
   ```bash
   streamlit run app.py
   ```

4. **Open your browser**
   
   The app will automatically open at `http://localhost:8501`

## üìñ Usage Guide

### Getting Started

1. **Select a Tokenizer Model**
   - Open the sidebar
   - Choose from available models (GPT-2, BERT, LLaMA 2, etc.)
   - Click "Load Tokenizer"
   - Wait for the model to download (first time only)

2. **Tokenize Your Text**
   - Enter or paste your text in the input area
   - Click the "üöÄ Tokenize" button
   - View instant results with detailed metrics

3. **Explore Results**
   - See token count, word count, and character statistics
   - Enable "Show Token Details" to see individual tokens
   - Enable "Show Token IDs" to see numerical token representations
   - Review token-to-word ratios and other analytics

4. **Export Your Data**
   - Download results as JSON for programmatic use
   - Export as CSV for spreadsheet analysis
   - Save tokens as TXT file for detailed review

### Available Models

| Model | Description | Best For | Size |
|-------|-------------|----------|------|
| **GPT-2** | OpenAI's GPT-2 tokenizer (BPE) | General purpose, fast | Small |
| **BERT** | Google's BERT tokenizer (WordPiece) | Understanding tasks | Small |
| **LLaMA 2** | Meta's LLaMA 2 tokenizer | Modern LLM applications | Large |
| **Mistral** | Mistral AI's tokenizer | Efficient LLM tokenization | Large |
| **FLAN-T5** | Google's T5 tokenizer | Text-to-text tasks | Medium |
| **OPT** | Meta's OPT tokenizer | Open pretrained transformers | Medium |
| **GPT-Neo** | EleutherAI's GPT-Neo tokenizer | Open-source GPT alternative | Medium |
| **T5** | Google's T5 tokenizer | Versatile text tasks | Small |

## üé® Interface Overview

### Main Dashboard
- **Input Area**: Large text area for entering content
- **Metrics Cards**: Visual display of key statistics
- **Token Display**: Interactive visualization of tokens
- **Export Section**: Multiple download options

### Sidebar
- **Model Selection**: Choose and load tokenizers
- **Display Options**: Toggle token details and IDs
- **Quick Stats**: Session statistics and history
- **Controls**: Clear history and reset options

## üìä Understanding the Results

### Metrics Explained

- **üéØ Tokens**: Number of tokens generated by the model
- **üìù Words**: Simple word count (space-separated)
- **üî§ Characters**: Total character count including spaces
- **üìÑ Sentences**: Estimated sentence count
- **üìä Token/Word Ratio**: Average tokens per word

### Why Token Count Matters

1. **API Pricing**: Most AI APIs charge based on tokens
2. **Model Limits**: Models have maximum token limits (e.g., GPT-4: 8K tokens)
3. **Performance**: More tokens = more processing time
4. **Context Windows**: Understanding how much text fits in context

### Token vs Word

Tokens are not the same as words:
- One word can be multiple tokens: `"unhappiness"` ‚Üí `["un", "happiness"]`
- One token can be part of a word: `"playing"` ‚Üí `["play", "ing"]`
- Special characters are often separate tokens
- Different models tokenize differently

## üõ†Ô∏è Technical Details

### Architecture

```
ai-tokenizer-pro/
‚îÇ
‚îú‚îÄ‚îÄ app.py                 # Main Streamlit application
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ README.md             # This file
‚îî‚îÄ‚îÄ .streamlit/
    ‚îî‚îÄ‚îÄ config.toml       # Streamlit configuration (optional)
```

### Dependencies

```txt
streamlit>=1.28.0
transformers>=4.30.0
torch>=2.0.0
pandas>=2.0.0
```

### Key Technologies

- **Streamlit**: Web application framework
- **Hugging Face Transformers**: Tokenizer library
- **PyTorch**: Backend for model loading
- **Pandas**: Data manipulation and export

## üéØ Use Cases

### For Developers
- Test tokenization before API calls
- Estimate API costs
- Debug tokenization issues
- Compare different tokenizers
- Optimize prompt engineering

### For Researchers
- Analyze text processing
- Study tokenization patterns
- Compare model behaviors
- Generate datasets with token counts

### For Content Creators
- Check text length for AI tools
- Optimize prompts for token limits
- Understand AI text processing
- Plan content within token budgets

## üí° Tips & Best Practices

1. **Model Selection**
   - Use GPT-2 for quick general-purpose tokenization
   - Use BERT for understanding-focused tasks
   - Use LLaMA 2/Mistral for modern LLM compatibility

2. **Performance**
   - Models are cached after first load
   - Larger models take longer to download initially
   - Token display may slow down with very large texts

3. **Token Optimization**
   - Shorter, clearer text = fewer tokens
   - Remove unnecessary punctuation
   - Use contractions wisely
   - Consider tokenization in prompt design

4. **Export Data**
   - JSON for programmatic use
   - CSV for analysis in Excel/Sheets
   - TXT for detailed token review

## üêõ Troubleshooting

### Common Issues

**Problem**: Model won't load
- **Solution**: Check your internet connection (first download)
- **Solution**: Ensure sufficient disk space (~500MB per model)
- **Solution**: Try a smaller model like GPT-2 or T5-small

**Problem**: Slow performance
- **Solution**: Disable "Show Token Details" for large texts
- **Solution**: Use a smaller/faster model
- **Solution**: Break text into smaller chunks

**Problem**: Out of memory error
- **Solution**: Reduce text size
- **Solution**: Use a smaller model
- **Solution**: Restart the application

## ü§ù Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Ideas for Contributions
- Add more tokenizer models
- Implement batch processing
- Add comparison mode for multiple tokenizers
- Create visualization charts
- Add multi-language support
- Implement token highlighting

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [Streamlit](https://streamlit.io/) for the amazing web framework
- [Hugging Face](https://huggingface.co/) for the Transformers library
- [OpenAI](https://openai.com/), [Google](https://google.com/), [Meta](https://meta.com/), and other organizations for open-source models

## üìß Contact

For questions, suggestions, or issues:
- Open an issue on GitHub
- Email: your.email@example.com
- Twitter: @yourusername

## üöÄ Future Enhancements

- [ ] Batch text processing
- [ ] Multi-tokenizer comparison view
- [ ] Token cost calculator for major APIs
- [ ] Custom tokenizer training
- [ ] API endpoint for programmatic access
- [ ] Dark mode theme
- [ ] Mobile app version
- [ ] Cloud deployment option

---

**Made with ‚ù§Ô∏è using Streamlit and Hugging Face**

*Star ‚≠ê this repository if you find it helpful!*